{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3be27ad-0cf8-4481-9b0b-cd1d17906538",
   "metadata": {},
   "source": [
    "**Eric Xiang #90612029**\n",
    "\n",
    "**Nishchay Ranjan #25257296**\n",
    "\n",
    "**Aryan Ghasemi #33475542**\n",
    "\n",
    "**Malcom Maxwell #97241418**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b3f137-06bf-4036-8d8b-6d16ebd9f81e",
   "metadata": {},
   "source": [
    "# Pulsar Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3486934-21fc-4844-bdee-952675ba9068",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "A pulsar is a magnetized rotating neutron star that emits electromagnetic radiation from its magnetic poles. The data set we will be using contains pulsar candidates collected during what's known as the \"High Time Resolution Universe Survey\". Pulsar emission spreads across the sky and produces a detectable pattern of broadband radio emission. However in practice almost all detections are caused by radio frequency interference and noise, making legitimate signals hard to find. Using this dataset, we will be creating an engine to try to predict whether a star is a pulsar or other. We want to ask: how accurately can our model predict if a star is a pulsar star? We will be using the HTRU2 data set, which contains 17,897 observations which were measured using RFI/noise.\n",
    "\n",
    "Our data can be found here: https://archive.ics.uci.edu/ml/datasets/HTRU2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae27e5f4-3dae-4344-aca3-8d6dc140d64a",
   "metadata": {},
   "source": [
    "## Method & Results\n",
    "\n",
    "Using UCI Machine Learning Repository's dataset on Pulsar stars, we plan to conduct a classification analysis using K-Nearest Neighbors to determine whether a star is a pulsar star or whether it is not. We will try to predict the variable Class using the predictors that are most suited to identifying a pulsar star, by training our KNN-Classification algorithm on those predictors. The final Pulsar KNN Model is going to be visualized as a scatterplot, with clear labels, coloured points depending on the class, and coloured points that indicates the decision of the classifier. Which will be compared to the true classification of the star to see whether our classification is good or bad. We have nine columns in our data set. 1) Mean of the integrated profile 2) Standard deviation of the integrated profile 3) Excess kurtosis of the integrated profile 4) Skewness of the integrated profile 5) Mean of the DM-SNR curve 6) Standard deviation of the DM-SNR curve 7) Excess kurtosis of the DM-SNR curve 8) Skewness of the DM-SNR curve 9) The classification of the observation. These will each be vetted to see which one will be best to distinguish pulsar stars from non-pulsar stars.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf66c6d8-fdb7-4bb9-a101-c6bbebefe0dd",
   "metadata": {},
   "source": [
    "#### Loading in initial libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb79f5b2-6568-4170-aee6-ef9cf0fe9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(GGally)\n",
    "library(testthat)\n",
    "library(digest)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "library(patchwork)\n",
    "options(repr.matrix.max.rows = 8)\n",
    "options(repr.plot.width=15, repr.plot.height=19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c0f946-9643-48fb-8e71-dd3ace3b23a8",
   "metadata": {},
   "source": [
    "## Wrangling Dataset\n",
    "\n",
    "In this part of the project, we want to wrangle our dataset so that it is tidy, and will be convenient for use later on when we are trying to make our classification model. We will do this by loading in the data, and applying the correct mutations to it so that it is tidy, which includes adding column names, changing certain variables to be a different class, renaming some values, and making the data easier to work with when typing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a3bc2e-8676-48d2-b9cd-e3814c5a325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in dataset, adding column headers, and renaming \"Class\" values from 0 and 1 to is_pulsar or is_not_pulsar to tidy up data\n",
    "\n",
    "paste(\"Table 1: Pulsar Data\")\n",
    "\n",
    "pulsar_data <- read_csv(\"https://raw.githubusercontent.com/KoiYouu/dcsi100_group_project/main/HTRU2/HTRU_2.csv\", col_names = FALSE, show_col_types = FALSE)\n",
    "colnames(pulsar_data) <- c(\"Mean_of _the_integrated_profile\", \n",
    "                           \"Standard_deviation_of_the_integrated_profile\",\n",
    "                           \"Excess_kurtosis_of_the_integrated_profile\",\n",
    "                           \"Skewness_of_the_integrated_profile\",\n",
    "                           \"Mean_of_the_DM-SNR_curve\",\n",
    "                           \"Standard_deviation_of_the_DM-SNR_curve\",\n",
    "                           \"Excess_kurtosis_of_the_DM-SNR_curve\",\n",
    "                           \"Skewness_of_the_DM-SNR_curve\",\n",
    "                           \"Class\")\n",
    "\n",
    "pulsar_data <- mutate(pulsar_data, Class = ifelse(Class == 1, \"is_pulsar\", \"is_not_pulsar\"), Class = as.factor(Class))\n",
    "pulsar_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5f43df-476d-446e-9950-5e0dd313e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming column headers to be easier to use when coding\n",
    "\n",
    "paste(\"Table 2: Pulsar Data With Updated Column Names\")\n",
    "\n",
    "colnames(pulsar_data) <- c('mean_profile', 'std_profile', 'kurtosis_profile', 'skewness_profile', 'mean_dmsnr',\n",
    "               'std_dmsnr', 'kurtosis_dmsnr', 'skewness_dmsnr', 'class')\n",
    "pulsar_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4c2c3e-927e-4387-ad9e-dce68eafb467",
   "metadata": {},
   "source": [
    "## Determining Which Variables To Use In Our KNN-Classification Algorithm\n",
    "\n",
    "The way we will determine which variables to use in our KNN-Classification algorithm is seeing which variables seem to differ a lot in value when a star is either a pulsar or not a pulsar star. The way we will do this is by using a violin graph to see which quantitative values would be the most useful for differentiating pulsar stars from non pulsar stars. We will also be splitting the data so that we are making proper predictive models without \"double counting\" the data and without seeing the test data. We can also see that there are 12168 observations that aren't pulsar stars, and 1255 that are pulsar_stars in our training dataset and the included 1 variable stats of our dataset, from this see that we may have to upscale our data as we see there is a large imbalance of pulsar stars to non-pulsar stars. In order to create a good classification model you generally should have a balanced set of data in order to make the best model. However, in our case we will not upscale our data which will be explained at the end of the project, as it will make more sense.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8116f69e-7236-45f3-a0af-8381373d9dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the training / testing split\n",
    "\n",
    "set.seed(2022)\n",
    "pulsar_split <- initial_split(pulsar_data, prop = 3/4, strata = class)  \n",
    "pulsar_train <- training(pulsar_split)   \n",
    "pulsar_test <- testing(pulsar_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9975be26-02bd-41e9-bd4d-d5977335d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting the basic data on our training set\n",
    "\n",
    "pulsar_info <- pulsar_train %>%\n",
    "    count(class)\n",
    "paste(\"Table 3: Count of Types Of Stars In Our Dataset\")\n",
    "pulsar_info\n",
    "\n",
    "paste(\"Table 4: One Variable Stats of Our Data\")\n",
    "summary(pulsar_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f7d239-6bd9-4555-a8d7-99b47e87e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the violin plots\n",
    "\n",
    "options(repr.plot.width=15, repr.plot.height=19)\n",
    "\n",
    "mean_profile_pulsar <- ggplot(pulsar_train, aes(x=class, y=mean_profile, fill = class)) + \n",
    "    geom_violin(width=1.7, position = \"dodge\")+\n",
    "    geom_boxplot(width=0.1, color=\"black\", alpha=0.6) +\n",
    "    labs(x=\"Star Type\", y = \"Mean of the integrated profile\")+\n",
    "    theme(text = element_text(size = 15))\n",
    "\n",
    "std_profile_pulsar <- ggplot(pulsar_train, aes(x=class, y=std_profile, fill = class)) + \n",
    "    geom_violin(width=1.7, position = \"dodge\")+\n",
    "    geom_boxplot(width=0.1, color=\"black\", alpha=0.6) +\n",
    "    labs(x=\"Star Type\", y = \"Standard deviation of the integrated profile\")+\n",
    "    theme(text = element_text(size = 15))\n",
    "\n",
    "kurtosis_profile_pulsar <- ggplot(pulsar_train, aes(x=class, y=kurtosis_profile, fill = class)) + \n",
    "    geom_violin(width=1.7, position = \"dodge\")+\n",
    "    geom_boxplot(width=0.1, color=\"black\", alpha=0.6) +\n",
    "    labs(x=\"Star Type\", y = \"Excess kurtosis of the integrated profile\")+\n",
    "    theme(text = element_text(size = 15))\n",
    "\n",
    "skewness_profile_pulsar <- ggplot(pulsar_train, aes(x=class, y=skewness_profile, fill = class)) + \n",
    "    geom_violin(width=1.7, position = \"dodge\")+\n",
    "    geom_boxplot(width=0.1, color=\"black\", alpha=0.6) +\n",
    "    labs(x=\"Star Type\", y = \"Skewness of the integrated profile\")+\n",
    "    theme(text = element_text(size = 15))\n",
    "\n",
    "mean_dmsnr_pulsar <- ggplot(pulsar_train, aes(x=class, y=mean_dmsnr, fill = class)) + \n",
    "    geom_violin(width=1.7, position = \"dodge\")+\n",
    "    geom_boxplot(width=0.1, color=\"black\", alpha=0.6) +\n",
    "    labs(x=\"Star Type\", y = \"Mean of the DM-SNR curve\")+\n",
    "    theme(text = element_text(size = 15))\n",
    "\n",
    "std_dmsnr_pulsar <- ggplot(pulsar_train, aes(x=class, y=std_dmsnr, fill = class)) + \n",
    "    geom_violin(width=1.7, position = \"dodge\")+\n",
    "    geom_boxplot(width=0.1, color=\"black\", alpha=0.6) +\n",
    "    labs(x=\"Star Type\", y = \"Standard deviation of the DM-SNR curve\")+\n",
    "    theme(text = element_text(size = 15))\n",
    "\n",
    "kurtosis_dmsnr_pulsar <- ggplot(pulsar_train, aes(x=class, y=kurtosis_dmsnr, fill = class)) + \n",
    "    geom_violin(width=1.7, position = \"dodge\")+\n",
    "    geom_boxplot(width=0.1, color=\"black\", alpha=0.6) +\n",
    "    labs(x=\"Star Type\", y = \"Excess kurtosis of the DM-SNR curve\")+\n",
    "    theme(text = element_text(size = 15))\n",
    "\n",
    "skewness_dmsnr_pulsar <- ggplot(pulsar_train, aes(x=class, y=skewness_dmsnr, fill = class)) + \n",
    "    geom_violin(width=1.7, position = \"dodge\")+\n",
    "    geom_boxplot(width=0.1, color=\"black\", alpha=0.6) +\n",
    "    labs(x=\"Star Type\", y = \"Skewness of the DM-SNR curve\")+\n",
    "    theme(text = element_text(size = 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e55efd-a57b-4390-812b-176ada0ba870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a subplot of the Violin graphs\n",
    "\n",
    "options(warn= -1)\n",
    "(mean_profile_pulsar | std_profile_pulsar)/\n",
    "(kurtosis_profile_pulsar | skewness_profile_pulsar)/\n",
    "(mean_dmsnr_pulsar | std_dmsnr_pulsar)/\n",
    "(kurtosis_dmsnr_pulsar | skewness_dmsnr_pulsar) + \n",
    "\n",
    "plot_annotation(\n",
    "    tag_levels = \"1\", tag_prefix = 'Fig. ',tag_sep = '.', tag_suffix = ':',\n",
    "    title = 'Violin Plot of Our Training Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ba55a9-0e55-410d-aa65-84787926e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE WARNINGS, wanted to use binwidth of 30 anyways\n",
    "\n",
    "ggpairs(pulsar_train) + \n",
    "ggtitle(\"Fig. 9: ggpairs of our training data\")+\n",
    "theme(text = element_text(size = 14), title = element_text(size = 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd8dbe4-d5a1-4629-a171-f1a0ba2505c6",
   "metadata": {},
   "source": [
    "## Preliminary Data Exploratory Analysis\n",
    "After looking at these violin plots we can see that the \"Mean of the integrated profile\", \"Excess kurtosis of the integrated profile\", \"Excess kurtosis of the DM-SNR curve\", and \"Standard deviation of the DM-SNR curve\" would be the best categories to train our engine on. This is backed up further when looking at our ggpairs graph as we see that there is a clear difference in these statistics when a star is a pulsar star vs a non-pulsar star. Therefore these 4 variables will be used in creating our KNN Classification engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac58068b-3b3a-4d63-9a2b-5b69ac0e9d39",
   "metadata": {},
   "source": [
    "## Creating the KNN Classification Engine / Finding The Best Value of $K$\n",
    "\n",
    "Before we even begin creating our KNN classification engine there are a few things we must do first. That is creating the recipe, making the specifications of our engine, and creating our cross-validation specifications. \n",
    " \n",
    "When creating the recipe we specify we are trying to classify the \"class\" variable, using the 4 previous variables we determined before; \"Mean of the integrated profile\", \"Excess kurtosis of the integrated profile\", \"Excess kurtosis of the DM-SNR curve\", and \"Standard deviation of the DM-SNR curve\". Next we then have to add to our recipe our scaling and centering of our data, otherwise certain pieces of data will have more voting power then other pieces of data. \n",
    " \n",
    "Next we make our classification engine specifications, where we tell our engine to classify datapoints using the K-nearest neighbours engine. \n",
    " \n",
    "Finally we make our cross validation specifications with 10 folds. Now we can move onto creating our KNN classification engine.\n",
    " \n",
    "When creating a KNN classification engine, we need to consider what the best value of $K$ is, to do so we must first test out a large range of K values by doing cross-validation and comparing the accuracies of each value of $K$ to find which value of $K$ gets us the highest accuracy. In our case we will be testing values for $K$ from $1$ to $10$, as each extra value of $K$ we test gets much more computationally expensive and would take very long. After finding the best $K$ value, by using v-fold cross validation with 10 folds to test for the best value of $K$, then we will use that determined $K$ value to create our final classification engine. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182fad19-5323-4f7e-872d-4ccb5165cef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the recipe, vfold, and engine\n",
    "\n",
    "set.seed(2022)\n",
    "\n",
    "pulsar_recipe <- recipe(class ~ mean_profile + kurtosis_profile + kurtosis_dmsnr + std_dmsnr, data = pulsar_train) |>\n",
    "  step_scale(all_predictors()) |>\n",
    "  step_center(all_predictors())\n",
    "\n",
    "\n",
    "pulsar_vfold <- vfold_cv(pulsar_train, v = 10, strata = class)\n",
    "\n",
    "gridvals <- tibble(neighbors = seq(1, 10))\n",
    "\n",
    "pulsar_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67f2b5b-44e0-4d42-8cd9-9e0e87db5ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting it all together in a worklist and collecting the metrics to graph\n",
    "\n",
    "set.seed(2022)\n",
    "\n",
    "pulsar_results <- workflow() |>\n",
    "  add_recipe(pulsar_recipe) |>\n",
    "  add_model(pulsar_spec) |>\n",
    "  tune_grid(resamples = pulsar_vfold, grid = gridvals) |>\n",
    "  collect_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f505246-a7ce-46b8-ab8d-b66e10f644a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arranging the metrics by highest accuracy and plotting\n",
    "\n",
    "paste(\"Table 5: Accuracy of Each K Value\")\n",
    "accuracies <- pulsar_results |>\n",
    "    filter(.metric == \"accuracy\") |>\n",
    "    arrange(desc(mean))\n",
    "accuracies\n",
    "\n",
    "options(repr.plot.height = 8, repr.plot.width = 14)\n",
    "\n",
    "cross_val_plot <- accuracies |> \n",
    "    ggplot(aes(x = neighbors, y = mean)) +\n",
    "    geom_point() +\n",
    "    geom_line() +\n",
    "    labs(x = \"Neighbors\", y = \"Accuracy Estimate\") +\n",
    "    scale_x_continuous(breaks = 1:10) +\n",
    "    theme(text = element_text(size = 20)) +\n",
    "    ggtitle(\"Fig. 10: Graph of The Accuracy of Each K Value\")\n",
    "\n",
    "cross_val_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906e74be-f2e2-4c85-a085-1a03b91ec060",
   "metadata": {},
   "source": [
    "## Creating The Final KNN Classification Engine\n",
    "\n",
    "As seen in the graph above the best $K$ neighbours seem to be either 5, 6, 7, and 8. In our case we will choose $K = 7$ as it seems to be a good middle value out of the 4 options. So now we will recreate our KNN classification engine but this time with $K = 7$ and collect the accuracy and confusion matrix of our predictions to see how accurate it is. We will then do a graph to visualize how frequently our KNN classification engine gets the correct or wrong classification. This time around nothing much changes, as we just reuse the same recipe, but specify $K = 7$ in our engine specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b7e449-c847-4456-af47-1c302e1dc1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding everything together in the new knn_spec, adding it to a workflow, getting the engine to predict on our test data, collecting the accuracy, \n",
    "# and finally making the confusion matrix and plotting the graph\n",
    "\n",
    "set.seed(2022)\n",
    "\n",
    "pulsar_final_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 7) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "pulsar_fit <- workflow() |>\n",
    "  add_recipe(pulsar_recipe) |>\n",
    "  add_model(pulsar_final_spec) |>\n",
    "  fit(data = pulsar_train)\n",
    "\n",
    "pulsar_fit\n",
    "\n",
    "pulsar_test_predictions <- predict(pulsar_fit, pulsar_test) |>\n",
    "    bind_cols(pulsar_test)\n",
    "\n",
    "pulsar_correctness <- predict(pulsar_fit, pulsar_test) |>\n",
    "    bind_cols(pulsar_test) |>\n",
    "    mutate(correct = .pred_class==class) |>\n",
    "    bind_cols(tibble(observation = 1:4475))\n",
    "\n",
    "accuracy <- pulsar_test_predictions |>\n",
    "    metrics(truth = class, estimate = .pred_class)|>\n",
    "    select(.metric, .estimate) |> \n",
    "    head(1)\n",
    "\n",
    "\n",
    "confusion_matrix <- pulsar_test_predictions |>\n",
    "  conf_mat(truth = class, estimate = .pred_class)\n",
    "\n",
    "options(repr.plot.height = 10, repr.plot.width = 24)\n",
    "\n",
    "pulsar_graph <- pulsar_correctness%>%\n",
    "    ggplot(aes(x=observation, y =std_dmsnr, colour = correct))+\n",
    "    geom_point(alpha = 0.8)+\n",
    "    labs(x = \"Unique Observation #\", y = \"True Classification\", colour = \"Correct Classification\")+\n",
    "    ggtitle(\"Fig. 11: Graph of Our Classification Engines Predictions\")+\n",
    "    theme(text = element_text(size = 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8554e15b-e0d6-4668-92bf-e3a347a7c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing off our accuracy, confusion matrix, and graph\n",
    "\n",
    "paste(\"Table 5: Accuracy of Our KNN Classification Engine\")\n",
    "accuracy\n",
    "paste(\"Table 6: Confusion Matrix of Our KNN Classification Engine\")\n",
    "confusion_matrix\n",
    "pulsar_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8936475a-bb64-406f-9a10-07ec52c536df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Final Analysis Of Our KNN Classification Model\n",
    "\n",
    "So our KNN Classification model has about a 97.9% accuracy when guessing pulsar stars based off of our predictors, in our test it had made 4383 correct predictions, while it made 27 false positives and 65 false negatives. We can see this too in the graph, as the number of blue dots (correct guesses) massively outnumbers the number of red dots (incorrect guesses). However, in reality our classification model is actually not as good as it first seems. The reason our accuracy is so high is because our data was skewed with non-pulsar star observations outnumbering our pulsar star observations by a large proportion. If we were to take the accuracy of each section of our confusion matrix, i.e the accuracy when just guessing for non-pulsar stars, and the accuracy for guessing just for pulsar stars; we see that our accuracy becomes 99.34% for guessing non-pulsar stars, and 83.07% for guessing pulsar stars. When all we care about is getting pulsar stars correct, this model becomes a lot worse as the accuracy of the thing we care about goes down from what seems to be a extremely high 97.94% accuracy to 83.07% This brings us to why we did not upsample even though we knew our dataset was skewed and could lead to a worse model.\n",
    "\n",
    "The first reason is it is difficult to implement upscaling, sometimes your model may be good enough without upscaling to use. This brings us to our second point, even though our model is not as perfect as we initially thought, it is still quite good as even the lowest end of the accuracy at 83.07% is relatively high. Our final reason to not upscale is that by upscaling we could potentially give our pulsar stars too much voting power, which in result actually would create a worse model overall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58cf371-0df9-48c3-8604-4a65c99426a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Discussion\n",
    "\n",
    "What we found while creating this project / classification engine are the types of methods to go about creating a good KNN classification engine from scratch, what a pulsar star is, many methods for visualization, and overall a better understanding of R and how to wrangle data as a whole. We also found out how well our KNN classification engine performed on our test data and how much this project improved our data science and R skills, which was to say was much better then we had expected.\n",
    "\n",
    "The reason it was much better than we had expected is that what we had expected to find was a very plain and easy copy and paste project where all of our code would be regurgitated from our worksheets / tutorials / textbook, with 0 thinking involved. However what we had found was quite far from that. While we still used the same base code from our worksheets / tutorials / textbook, we had to put a lot of thought into how exactly to use the code, as it wasn't stated what variables to choose, or the K value we needed to use. This allowed for us to improve our critical thinking skills, R skills, and other general data science abilities. Another thing we had not expected to find was that our KNN classification engine had such good accuracy. We expected a low 50-60% accuracy as the predicting of pulsar stars seemed to be a difficult problem that such a simple algorithm could not do well. However, our expectations were crushed when we made our final KNN classification engine and collected its accuracy. It was a staggering 97.9% on the high end and a still relatively high 83.07% accuracy after some further thinking. Even though its accuracy was worse than the initial value we collected, it was still way higher than what we expected.\n",
    "\n",
    "The impact of these findings can help us in future group projects, data sciences courses, coding in R, and most importantly real life uses. This method can be used to determine if the stars that are discovered are pulsar or not. This method is efficient and fast, and it would have benefits for scientists. We can change the model and use a similar code to determine the types of different stars. We arranged the data into sequences according to their common characteristics and used the information to label the data as a pulsar or not pulsar. This technique could be used for other data as well.\n",
    "\n",
    "Some future questions that came out of making this project were how to improve our model, as obviously we thought a higher accuracy model would get us a better mark (this doesn't seem to be the case anymore from you Q&A), how else could we have approached this classification question which included trying with a different engine or different predictors as our variables, and lastly what could we have done to better improve our visualization of our classification model. Although the current visualizations are pretty good we thought they could be improved more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5631d0c1-bbc2-415e-973c-873edbc694fb",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "All References Done In A APA7 Style Citation;\n",
    "\n",
    "UCI Machine Learning Repository: HTRU2 Data Set. (n.d.). Archive.ics.uci.edu. https://archive.ics.uci.edu/ml/datasets/HTRU2\n",
    "\n",
    "Function reference. (n.d.). Ggplot2.Tidyverse.org. https://ggplot2.tidyverse.org/reference/\n",
    "\n",
    "The Composer of Plots. (n.d.). Patchwork.data-Imaginist.com. Retrieved December 7, 2022, from https://patchwork.data-imaginist.com/index.html\n",
    "\n",
    "Peng, T. T., Trevor Campbell, and Melissa Lee Foreword by Roger. (n.d.). Data Science. In datasciencebook.ca. Retrieved December 7, 2022, from https://datasciencebook.ca/\n",
    "\n",
    "omertahi. (2022, November 3). DSCI100_Review_Session/Review Session 2.ipynb at main · omertahi/DSCI100_Review_Session. GitHub. https://github.com/omertahi/DSCI100_Review_Session/blob/main/Review%20Session%202.ipynb\n",
    "\n",
    "omertahi. (2022, October 4). DSCI100_Review_Session/Review Session.ipynb at main · omertahi/DSCI100_Review_Session. GitHub. https://github.com/omertahi/DSCI100_Review_Session/blob/main/Review%20Session.ipynb\n",
    "\n",
    "‌Guide to accuracy, precision, and recall. (n.d.). Mage. https://www.mage.ai/blog/definitive-guide-to-accuracy-precision-recall-for-product-developers\n",
    "\n",
    "‌Posit. (n.d.). Posit. https://posit.co/resources/cheatsheets/\n",
    "\n",
    "‌EarthSky | What’s a pulsar and why does it pulse? (2022, July 15). Earthsky.org. https://earthsky.org/space/what-is-a-pulsar/\n",
    "\n",
    "‌Calla Cofield. (2016, April 22). What Are Pulsars? Space.com; Space. https://www.space.com/32661-pulsars.html\n",
    "\n",
    "‌Predicting Pulsars with ML Algorithms. (n.d.). Kaggle.com. Retrieved December 7, 2022, from https://www.kaggle.com/code/manchunhui/predicting-pulsars-with-ml-algorithms\n",
    "\n",
    "‌Delatte, T. (n.d.). Pulsars Detection with HTRU2 Dataset. Thomasdelatte.github.io. https://thomasdelatte.com/2020/04/pulsars/\n",
    "\n",
    "\n",
    "‌"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
